{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #### REMOVE THIS LINE WHEN CUDA CONFIG IS FIXED\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import gym_snake\n",
    "import json\n",
    "import importlib\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils.Buffer import ReplayBuffer\n",
    "from utils.Conv import ConvHead\n",
    "from rl.models import get_policy_architecture, get_value_architecture, get_vision_architecture\n",
    "from algos.PPO import PPO_agent\n",
    "from algos.DQN import DQN_agent\n",
    "from utils.Loader import load_agent\n",
    "\n",
    "# %load_ext line_profiler\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nagent = load_agent(\\n    os.path.join(\\'..\\', \\'configs\\', \\'cartpole.json\\'),\\n    run_name=\"cartpole-DQN-load_test\",\\n    ckpt_folder=os.path.join(\\'..\\', \\'checkpoints\\')\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "agent = load_agent(\n",
    "    os.path.join('..', 'configs', 'cartpole.json'),\n",
    "    run_name=\"cartpole-DQN-load_test\",\n",
    "    ckpt_folder=os.path.join('..', 'checkpoints')\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhist = []\\nagent.load_from_checkpoint()\\nhist += agent.train(100, t_max=1000, display=True)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "hist = []\n",
    "agent.load_from_checkpoint()\n",
    "hist += agent.train(100, t_max=1000, display=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tetris = importlib.import_module('pytris-effect.src.gameui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'snake'\n",
    "action = 'train'\n",
    "algo = ('DDQN', 'Dueling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_fp = os.path.join('..', 'configs', run_name + '.json')\n",
    "with open(cfg_fp, 'r') as f:\n",
    "    config = json.load(f)\n",
    "ckpt_folder = os.path.join('..', 'checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = config['env']\n",
    "if run_name == 'tetris':\n",
    "    env = tetris.GameUI(graphic_mode=False, its_per_sec=2, sec_per_tick=0.5)\n",
    "else:\n",
    "    env = gym.make(env_name).env if 'use_raw_env' in config else gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(arr):\n",
    "    scaling = 30\n",
    "    data = np.zeros((scaling*arr.shape[0], scaling*arr.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            for k in range(data.shape[2]):\n",
    "                data[i,j,k] = arr[i//scaling,j//scaling,k]\n",
    "    img = Image.fromarray(data, 'RGB')\n",
    "    # img.save('my.png')\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if action == 'evaluate':\n",
    "    %lprun -f env.drawMatrix env.drawMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if action == 'evaluate':\n",
    "    arr = env.reset()[::10,::10,:]\n",
    "    img = Image.fromarray(arr, 'RGB')\n",
    "    img.show()\n",
    "    #show_img(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    action = 1\n",
    "    obs, reward, dn, info = env.step(action)\n",
    "    show_img(obs)\n",
    "    print(reward, dn, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_step():\n",
    "    _, _, dn, _ = env.step(random.choice(range(7)))\n",
    "    if dn:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit do_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f env.get_obs do_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_policy_architecture(env_name, algo=algo)\n",
    "if 'DQN' in \"\\n\".join(algo):\n",
    "    target = tf.keras.models.clone_model(model)\n",
    "else:\n",
    "    value = get_value_architecture(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DQN' in \"\\n\".join(algo):\n",
    "    agent = DQN_agent(\n",
    "        model,\n",
    "        # (TODO): Move args for ReplayBuffer into DQN\n",
    "        ReplayBuffer(config.get(\"max_buf_size\", 20000), mode='uniform'),\n",
    "        target=target,\n",
    "        env=env,\n",
    "        mode=('DDQN'), # 'PER'\n",
    "        learning_rate=config['learning_rate'],\n",
    "        batch_size=config['batch_size'],\n",
    "        update_steps=1,\n",
    "        update_freq=4,\n",
    "        multistep=5,\n",
    "        alpha=1.5,\n",
    "        beta=1.0,\n",
    "        gamma=0.95,\n",
    "        target_delay=1000,\n",
    "        delta=1.0,\n",
    "        # delta=0.000003,\n",
    "        env_name=config['env_name'],\n",
    "        algo_name='DQN',\n",
    "        ckpt_folder=ckpt_folder,\n",
    "        run_name='snake-DQN-pretrain-hard_update-uniform-multistep5-6'\n",
    "    )\n",
    "elif 'PPO' in \"\\n\".join(algo):\n",
    "    agent = PPO_agent(\n",
    "        model,\n",
    "        value,\n",
    "        env=env,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        minibatch_size=config['minibatch_size'],\n",
    "        gamma=0.99,\n",
    "        env_name=config['env_name'],\n",
    "        run_name='snake-PPO-pretrain',\n",
    "        ckpt_folder=ckpt_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = config['t_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_buf = []\n",
    "\n",
    "def collect_rollout(env, t_max, policy):\n",
    "    s = agent.preprocess(env.reset())\n",
    "    for t in range(t_max):\n",
    "        act = policy(s)\n",
    "        ss, r, dn, _ = env.step(agent.action_wrapper(act))\n",
    "        ss = agent.preprocess(ss)\n",
    "        p_buf.append([s, ss])\n",
    "        s = ss\n",
    "        if dn:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 491.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 15340 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ee2c4737424628ab99ef71a051bf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: [0.22921282 0.26290193 0.12300461 0.12752995 0.11707391 0.15183185\n",
      " 0.12748024 0.09673619 0.19803968 0.16643393 0.13425826 0.1545998\n",
      " 0.08676375 0.07365814 0.1318234  0.16210482 0.08700682 0.10762814\n",
      " 0.07453926 0.10087536 0.10958755 0.14552695 0.14574803 0.1252699\n",
      " 0.14847773 0.13899545 0.11840709 0.1272275  0.17439987 0.20915326\n",
      " 0.19524778 0.17320062 0.15796182 0.12654833 0.12276284 0.11939698\n",
      " 0.11618607 0.11209881 0.11710346 0.13498604 0.1002903  0.0934117\n",
      " 0.10714595 0.13876866 0.09840295 0.10085947 0.12309004 0.12536836\n",
      " 0.09456156 0.12299266 0.17776307 0.16987197 0.18386348 0.1752637\n",
      " 0.11528827 0.11021537 0.12458029 0.11667293 0.11671758 0.11232901\n",
      " 0.17166162 0.2000716  0.1212991  0.10975193 0.12694229 0.14155324\n",
      " 0.13857977 0.1081904  0.1234675  0.16209778 0.20601407 0.20295605\n",
      " 0.14436077 0.1246126  0.16309425 0.13841558 0.10621558 0.11281113\n",
      " 0.19111906 0.22662428 0.11762059 0.12247466 0.133143   0.146335\n",
      " 0.10317672 0.09064768 0.15939142 0.14965695 0.08122177 0.0916882\n",
      " 0.09860855 0.10576729 0.11970737 0.15649435 0.17866322 0.18566734\n",
      " 0.11614946 0.13920726 0.12039035 0.10962033 0.121477   0.17139317\n",
      " 0.21123543 0.18676458 0.12392735 0.12202931 0.18281822 0.19451742\n",
      " 0.1614355  0.14032558 0.15664366 0.1465233  0.15132311 0.16169146\n",
      " 0.1293918  0.12059636 0.1375499  0.1274649  0.12911816 0.13720274\n",
      " 0.14205073 0.18313554 0.11334085 0.12981252 0.11674437 0.11418711\n",
      " 0.1198211  0.12620646]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79d9a6298d4425995fffac632e720d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loss: [0.04029174 0.04489665 0.04832982 0.04216554 0.04574964 0.03660686\n",
      " 0.06399546 0.0709819  0.04659969 0.05755356 0.02703181 0.0410537\n",
      " 0.06195014 0.05658235 0.05925698 0.06547911 0.0494944  0.03984912\n",
      " 0.0590899  0.0894155  0.04201325 0.03549167 0.05642061 0.05546975\n",
      " 0.04336316 0.0411713  0.0590832  0.05630757 0.06264707 0.05360743\n",
      " 0.06640325 0.05431776 0.0435481  0.05724861 0.03452111 0.05112505\n",
      " 0.04369593 0.06383638 0.03901803 0.03699951 0.0457134  0.03315241\n",
      " 0.06023696 0.0682625  0.04574271 0.04599875 0.06782895 0.0663662\n",
      " 0.05664791 0.04524819 0.03904472 0.05024296 0.05516161 0.07909564\n",
      " 0.05928591 0.05901829 0.05771784 0.05427924 0.06338928 0.06343716\n",
      " 0.07984376 0.07576228 0.0369681  0.03674037 0.0592887  0.05927235\n",
      " 0.07247845 0.0512591  0.05222975 0.05634772 0.06515016 0.0582396\n",
      " 0.03207615 0.0326538  0.0630405  0.06188006 0.03117936 0.0262541\n",
      " 0.04549374 0.04857834 0.06109101 0.05544307 0.04180067 0.04443981\n",
      " 0.04023527 0.03678816 0.03933122 0.05109398 0.05258431 0.04756308\n",
      " 0.03068254 0.03864561 0.06197482 0.06393167 0.05458447 0.0717453\n",
      " 0.04342516 0.03538941 0.04394252 0.04974708 0.06629949 0.06184773\n",
      " 0.03999391 0.05641235 0.0467241  0.03678258 0.0679082  0.06379355\n",
      " 0.03389505 0.03581477 0.03835156 0.04615813 0.02932126 0.03656944\n",
      " 0.04756789 0.03955679 0.04653818 0.04784795 0.03754628 0.05227334\n",
      " 0.06485985 0.04144435 0.03925402 0.0519116  0.05446792 0.04726904\n",
      " 0.04678822 0.02780344]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9c7545f5294d4fa1f996648653bfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Loss: [0.04300529 0.05741789 0.02949149 0.04367517 0.03796415 0.03583062\n",
      " 0.03479189 0.0499949  0.04471017 0.04257011 0.02320085 0.03129834\n",
      " 0.04933061 0.04795079 0.04829975 0.04549236 0.04839857 0.04308864\n",
      " 0.04128105 0.03332819 0.06758244 0.05519855 0.04625449 0.05746291\n",
      " 0.03083989 0.02950994 0.04948584 0.0449586  0.03712494 0.04419211\n",
      " 0.03414374 0.04122782 0.07662147 0.05575178 0.0525094  0.05502785\n",
      " 0.06685682 0.0702917  0.0658897  0.05627571 0.06856452 0.04952583\n",
      " 0.04250816 0.04239889 0.04973667 0.05461917 0.03239356 0.03538334\n",
      " 0.03866177 0.04959716 0.0182526  0.02116719 0.0453904  0.04593368\n",
      " 0.03196087 0.05328958 0.02721568 0.02692061 0.05168466 0.04138392\n",
      " 0.0228628  0.02629223 0.04111489 0.03645758 0.07712051 0.05757553\n",
      " 0.01562515 0.01941114 0.04824956 0.04054635 0.04647271 0.0326884\n",
      " 0.06433125 0.04401124 0.05352043 0.05576983 0.03709669 0.03177122\n",
      " 0.02647421 0.04239442 0.04917867 0.03572547 0.027128   0.02561799\n",
      " 0.05509416 0.06412733 0.04005285 0.03700274 0.0488571  0.07132764\n",
      " 0.05734005 0.05890092 0.05182405 0.04628287 0.0640972  0.04792088\n",
      " 0.03771187 0.03011895 0.03301127 0.03495697 0.05485509 0.03938724\n",
      " 0.04877285 0.04979164 0.02028786 0.02331093 0.06027715 0.05649278\n",
      " 0.04364257 0.04576727 0.02908071 0.04018746 0.06386343 0.06249291\n",
      " 0.03374542 0.04314409 0.03422731 0.04393383 0.03848634 0.03266166\n",
      " 0.04122615 0.02700927 0.05836457 0.04808395 0.03308469 0.03992542\n",
      " 0.02998287 0.03878407]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7bc1f2d03b446a9ccc6ae85135d76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Loss: [0.05036193 0.05223871 0.03915145 0.04665126 0.04789048 0.04297912\n",
      " 0.02845554 0.02402087 0.03389608 0.03468594 0.05227201 0.04506958\n",
      " 0.05283229 0.05907467 0.03919463 0.03084424 0.04246049 0.04145984\n",
      " 0.0454597  0.04823953 0.03712408 0.02895919 0.04885987 0.05138497\n",
      " 0.04227104 0.02642248 0.0407482  0.05470575 0.03214408 0.02913301\n",
      " 0.04885745 0.04802742 0.03768533 0.04337101 0.05466463 0.06225794\n",
      " 0.0521436  0.04176433 0.06057215 0.05670295 0.03673268 0.02920806\n",
      " 0.02992549 0.03115466 0.04034725 0.03978996 0.04650857 0.05453834\n",
      " 0.04185672 0.0306126  0.03795753 0.05249297 0.035193   0.04538126\n",
      " 0.04292319 0.06119847 0.03174902 0.02030126 0.02590664 0.02751601\n",
      " 0.04405541 0.03668127 0.03525884 0.0280512  0.04851555 0.04703248\n",
      " 0.04137217 0.05256812 0.04200057 0.03598359 0.04470385 0.027852\n",
      " 0.04288898 0.0471281  0.03892104 0.03024575 0.04174748 0.03988989\n",
      " 0.03891396 0.02401215 0.032889   0.03086352 0.03550171 0.04679535\n",
      " 0.04869046 0.05822576 0.03319585 0.04736598 0.07493982 0.05974649\n",
      " 0.04436422 0.04294638 0.07960316 0.06639409 0.02696263 0.03254787\n",
      " 0.03500067 0.0357705  0.04379192 0.02324947 0.03999913 0.04214443\n",
      " 0.03178763 0.03595716 0.03843116 0.04346437 0.02964134 0.02737777\n",
      " 0.04150723 0.05134081 0.03460296 0.02606665 0.04289107 0.04590978\n",
      " 0.05618372 0.05677715 0.05924679 0.04435712 0.02528274 0.04198882\n",
      " 0.03025321 0.02354806 0.0435643  0.04518277 0.0319262  0.04018947\n",
      " 0.03204606 0.03574098]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122f1db3295948f9af68788776e85143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Loss: [0.03115119 0.02337028 0.03250003 0.02595126 0.04767809 0.05652824\n",
      " 0.03612578 0.0319135  0.03194577 0.03662231 0.04242696 0.04907579\n",
      " 0.05662163 0.04818492 0.06163044 0.05637051 0.03125926 0.02312207\n",
      " 0.05064761 0.04791186 0.07090805 0.05862759 0.04892192 0.04956776\n",
      " 0.04378021 0.04115648 0.07376156 0.07683154 0.03648309 0.03910259\n",
      " 0.06425255 0.05342804 0.02642041 0.04181585 0.0381895  0.04179161\n",
      " 0.03318887 0.02777741 0.02751732 0.03660753 0.0619569  0.04668658\n",
      " 0.04168559 0.04625313 0.06463359 0.07359751 0.03982521 0.03723287\n",
      " 0.04112272 0.04155536 0.02494253 0.02785578 0.04381517 0.03780241\n",
      " 0.03077905 0.04271168 0.02545066 0.03186544 0.04462107 0.03396027\n",
      " 0.04067665 0.03453539 0.02213425 0.02525274 0.04739132 0.04124903\n",
      " 0.04064483 0.0355098  0.0369911  0.04060873 0.03594515 0.03693855\n",
      " 0.04744289 0.04475193 0.03527401 0.03694947 0.02679177 0.0288363\n",
      " 0.02706868 0.02149264 0.06025117 0.04886607 0.02505201 0.02392531\n",
      " 0.04394412 0.06457856 0.02689337 0.02186836 0.02375817 0.03312591\n",
      " 0.0519178  0.04873762 0.04211339 0.03504686 0.05353236 0.05221468\n",
      " 0.05078432 0.06993115 0.04837386 0.04368496 0.04624753 0.04910936\n",
      " 0.05449877 0.04335006 0.0191862  0.02820228 0.03893601 0.03317327\n",
      " 0.02269799 0.02944414 0.03590573 0.04210305 0.04068988 0.0327357\n",
      " 0.04632562 0.0433437  0.0224486  0.03616436 0.04879749 0.04034727\n",
      " 0.0279597  0.03278182 0.05284068 0.05365604 0.05892999 0.04695759\n",
      " 0.0204043  0.02337752]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928529c1362c46ebbf1d6ffb6bb549ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Loss: [0.03618854 0.04181621 0.04324885 0.04190331 0.05366328 0.0531702\n",
      " 0.07341421 0.07209782 0.04251619 0.04543882 0.06115434 0.03894209\n",
      " 0.03867267 0.04320775 0.02820909 0.01705811 0.0390548  0.03646542\n",
      " 0.03399859 0.03570601 0.05371594 0.05006413 0.04925235 0.06753691\n",
      " 0.041731   0.05494013 0.04512675 0.06199396 0.02812941 0.03949092\n",
      " 0.04091566 0.04482966 0.0588223  0.05762515 0.02738499 0.03746816\n",
      " 0.02943849 0.02849346 0.03074321 0.02956468 0.04450908 0.04128332\n",
      " 0.04578294 0.04807186 0.02662081 0.01946401 0.02332863 0.02478257\n",
      " 0.02773257 0.02531618 0.04134595 0.04525616 0.05078652 0.03732973\n",
      " 0.0490083  0.05443706 0.03562012 0.04541828 0.06864782 0.05847213\n",
      " 0.04511335 0.03765792 0.0427177  0.03425774 0.05188077 0.06697496\n",
      " 0.03938233 0.04603267 0.03688255 0.03164749 0.03318258 0.04038472\n",
      " 0.0363289  0.03798346 0.03690832 0.04066602 0.04289086 0.04217483\n",
      " 0.02029346 0.01922898 0.01320202 0.0170903  0.06065333 0.04677466\n",
      " 0.03525647 0.03658151 0.0352665  0.03376456 0.02143495 0.02365805\n",
      " 0.03916308 0.03372716 0.03616001 0.02581403 0.03754917 0.04188196\n",
      " 0.04423384 0.03812638 0.03702899 0.03745636 0.04312913 0.04636024\n",
      " 0.07032433 0.08816901 0.04459485 0.02986366 0.02212971 0.02122051\n",
      " 0.06141582 0.05000652 0.03454509 0.0308747  0.03824969 0.05219126\n",
      " 0.02297803 0.03671375 0.0477315  0.05082776 0.04401537 0.03885562\n",
      " 0.02955224 0.02469413 0.02196039 0.02657956 0.02725372 0.04075566\n",
      " 0.0259262  0.02604451]\n"
     ]
    }
   ],
   "source": [
    "pretrain = True\n",
    "if pretrain and action == 'train': # only necessary for tasks on raw pixels (vision)\n",
    "    embed = get_vision_architecture(env_name)\n",
    "    # get some data from random interactions with the env\n",
    "    for i in tqdm(range(500)):\n",
    "        collect_rollout(env, t_max, lambda x: np.random.choice(4))\n",
    "    print(\"Collected {} samples\".format(len(p_buf)))\n",
    "    head = ConvHead(embed, p_buf)\n",
    "    head.train(6)\n",
    "    \n",
    "    out = head.model.layers[-2].output\n",
    "    vision = tf.keras.Model(inputs=head.model.input, outputs=out)\n",
    "    pretrained_model = get_policy_architecture(env_name, algo=algo, pretrain=vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_from_checkpoint()\n",
    "### WARNING: will overwrite existing runs\n",
    "hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 478.33it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8b8a81331f4407911b93b4dfb874e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Average reward: -1.0\n",
      "Predicted reward: [[-0.17022735 -0.15910876 -0.14909872 -0.13629511]]\n",
      "Buffer size: 14991\n",
      "Saving to checkpoint...\n",
      "[10] Average reward: -1.0\n",
      "Predicted reward: [[-0.13725631 -0.05270778 -0.086668   -0.05755933]]\n",
      "Buffer size: 15080\n",
      "Saving to checkpoint...\n",
      "[15] Average reward: -1.0\n",
      "Predicted reward: [[-0.07598333 -0.01828219 -0.05113086 -0.03390285]]\n",
      "Buffer size: 15129\n",
      "Saving to checkpoint...\n",
      "[20] Average reward: -1.0\n",
      "Predicted reward: [[-0.08268044 -0.0236209  -0.04741701 -0.01205611]]\n",
      "Buffer size: 15200\n",
      "Saving to checkpoint...\n",
      "[25] Average reward: -1.0\n",
      "Predicted reward: [[-0.07056684 -0.04058401 -0.01149733 -0.00271421]]\n",
      "Buffer size: 15275\n",
      "Saving to checkpoint...\n",
      "[30] Average reward: -1.0\n",
      "Predicted reward: [[-0.06655702  0.01047969 -0.04606633 -0.00151416]]\n",
      "Buffer size: 15434\n",
      "Saving to checkpoint...\n",
      "[35] Average reward: -1.0\n",
      "Predicted reward: [[-0.06103962 -0.01771689 -0.037844   -0.04822411]]\n",
      "Buffer size: 15521\n",
      "Saving to checkpoint...\n",
      "[40] Average reward: -0.8\n",
      "Predicted reward: [[-0.06175682  0.00133009  0.00154732  0.04995145]]\n",
      "Buffer size: 15610\n",
      "Saving to checkpoint...\n",
      "[45] Average reward: -1.0\n",
      "Predicted reward: [[-0.0680142   0.01282228 -0.0301939   0.00712653]]\n",
      "Buffer size: 15769\n",
      "Saving to checkpoint...\n",
      "[50] Average reward: -1.0\n",
      "Predicted reward: [[-0.03461979  0.01432735  0.02193254  0.04553529]]\n",
      "Buffer size: 15836\n",
      "Saving to checkpoint...\n",
      "[55] Average reward: -1.0\n",
      "Predicted reward: [[0.01089253 0.01002722 0.02131005 0.06660601]]\n",
      "Buffer size: 15982\n",
      "Saving to checkpoint...\n",
      "[60] Average reward: -0.8\n",
      "Predicted reward: [[0.02752872 0.02312491 0.07950141 0.09893957]]\n",
      "Buffer size: 16081\n",
      "Saving to checkpoint...\n",
      "[65] Average reward: -1.0\n",
      "Predicted reward: [[-0.06505883 -0.00998182 -0.10186074 -0.04593171]]\n",
      "Buffer size: 16166\n",
      "Saving to checkpoint...\n",
      "[70] Average reward: -1.0\n",
      "Predicted reward: [[-0.06653212  0.02816404 -0.05846502 -0.03916316]]\n",
      "Buffer size: 16272\n",
      "Saving to checkpoint...\n",
      "[75] Average reward: -0.8\n",
      "Predicted reward: [[-0.02179589 -0.03898487  0.02494733  0.04475904]]\n",
      "Buffer size: 16465\n",
      "Saving to checkpoint...\n",
      "[80] Average reward: -1.0\n",
      "Predicted reward: [[-0.1554247  -0.04010846 -0.05726147 -0.06025431]]\n",
      "Buffer size: 16588\n",
      "Saving to checkpoint...\n",
      "[85] Average reward: -1.0\n",
      "Predicted reward: [[0.03768213 0.0280205  0.05241812 0.02849689]]\n",
      "Buffer size: 16710\n",
      "Saving to checkpoint...\n",
      "[90] Average reward: -1.0\n",
      "Predicted reward: [[0.1726571  0.02749566 0.11085538 0.16215256]]\n",
      "Buffer size: 16981\n",
      "Saving to checkpoint...\n",
      "[95] Average reward: -0.8\n",
      "Predicted reward: [[-0.17666465 -0.00234961 -0.07169479 -0.05781425]]\n",
      "Buffer size: 17306\n",
      "Saving to checkpoint...\n",
      "[100] Average reward: -0.8\n",
      "Predicted reward: [[-0.19390604 -0.0682288  -0.10235458 -0.08488211]]\n",
      "Buffer size: 17441\n",
      "Saving to checkpoint...\n",
      "[105] Average reward: -0.8\n",
      "Predicted reward: [[-0.10060075  0.01056097 -0.11273487  0.04179194]]\n",
      "Buffer size: 17592\n",
      "Saving to checkpoint...\n",
      "[110] Average reward: -1.0\n",
      "Predicted reward: [[-0.05207612 -0.00063594 -0.04191054  0.01085431]]\n",
      "Buffer size: 17726\n",
      "Saving to checkpoint...\n",
      "[115] Average reward: -1.0\n",
      "Predicted reward: [[-0.02071571  0.01540926 -0.09966161 -0.00461916]]\n",
      "Buffer size: 18099\n",
      "Saving to checkpoint...\n",
      "[120] Average reward: -0.8\n",
      "Predicted reward: [[-0.09337039 -0.07739302  0.01762145 -0.06601451]]\n",
      "Buffer size: 18366\n",
      "Saving to checkpoint...\n",
      "[125] Average reward: -0.6\n",
      "Predicted reward: [[-0.12645967 -0.04238431 -0.04283363  0.01699625]]\n",
      "Buffer size: 18466\n",
      "Saving to checkpoint...\n",
      "[130] Average reward: -1.0\n",
      "Predicted reward: [[0.06528394 0.02357023 0.11046986 0.00752958]]\n",
      "Buffer size: 18680\n",
      "Saving to checkpoint...\n",
      "[135] Average reward: -1.0\n",
      "Predicted reward: [[-0.1820545  -0.07251819 -0.15502474 -0.04636005]]\n",
      "Buffer size: 18934\n",
      "Saving to checkpoint...\n",
      "[140] Average reward: -1.0\n",
      "Predicted reward: [[-0.14372371 -0.03101981 -0.10207531 -0.05453119]]\n",
      "Buffer size: 19109\n",
      "Saving to checkpoint...\n",
      "[145] Average reward: -1.0\n",
      "Predicted reward: [[-0.03730741 -0.03855641  0.06583866 -0.01065043]]\n",
      "Buffer size: 19382\n",
      "Saving to checkpoint...\n",
      "[150] Average reward: -0.6\n",
      "Predicted reward: [[-0.02543371 -0.04357293  0.04672982 -0.01935564]]\n",
      "Buffer size: 19667\n",
      "Saving to checkpoint...\n",
      "[155] Average reward: -1.0\n",
      "Predicted reward: [[-0.09549994 -0.023388    0.00811643 -0.12349815]]\n",
      "Buffer size: 19914\n",
      "Saving to checkpoint...\n",
      "[160] Average reward: -1.0\n",
      "Predicted reward: [[-0.1558905  -0.16729665 -0.04244717 -0.21947455]]\n",
      "Buffer size: 20133\n",
      "Saving to checkpoint...\n",
      "[165] Average reward: -0.8\n",
      "Predicted reward: [[ 0.04506081 -0.09304883  0.14952198 -0.03912931]]\n",
      "Buffer size: 20367\n",
      "Saving to checkpoint...\n",
      "[170] Average reward: -1.0\n",
      "Predicted reward: [[-0.13846976 -0.17552714 -0.12227647 -0.15233555]]\n",
      "Buffer size: 20625\n",
      "Saving to checkpoint...\n",
      "[175] Average reward: -0.8\n",
      "Predicted reward: [[-0.00632892 -0.05006413 -0.10039486 -0.07541111]]\n",
      "Buffer size: 20833\n",
      "Saving to checkpoint...\n",
      "[180] Average reward: -0.6\n",
      "Predicted reward: [[ 0.00316342 -0.16048555  0.04448511  0.0026031 ]]\n",
      "Buffer size: 21055\n",
      "Saving to checkpoint...\n",
      "[185] Average reward: -0.8\n",
      "Predicted reward: [[ 0.10590654  0.00975543  0.04393537 -0.01642196]]\n",
      "Buffer size: 21683\n",
      "Saving to checkpoint...\n",
      "[190] Average reward: -0.8\n",
      "Predicted reward: [[-0.1939232  -0.21594203 -0.43958136 -0.12921825]]\n",
      "Buffer size: 22115\n",
      "Saving to checkpoint...\n",
      "[195] Average reward: -0.6\n",
      "Predicted reward: [[-0.02847175 -0.06382366  0.01405952 -0.06937192]]\n",
      "Buffer size: 22288\n",
      "Saving to checkpoint...\n",
      "[200] Average reward: -0.8\n",
      "Predicted reward: [[0.18069084 0.20262682 0.1390538  0.0109316 ]]\n",
      "Buffer size: 22577\n",
      "Saving to checkpoint...\n",
      "[205] Average reward: -0.8\n",
      "Predicted reward: [[-0.0722683  -0.06460652 -0.01147404 -0.03660683]]\n",
      "Buffer size: 23996\n",
      "Saving to checkpoint...\n",
      "[210] Average reward: -0.6\n",
      "Predicted reward: [[ 0.01894373  0.03387257  0.04363431 -0.06067882]]\n",
      "Buffer size: 25266\n",
      "Saving to checkpoint...\n",
      "[215] Average reward: -1.0\n",
      "Predicted reward: [[-0.0881497  -0.14792165 -0.14381915 -0.1079664 ]]\n",
      "Buffer size: 25624\n",
      "Saving to checkpoint...\n",
      "[220] Average reward: -0.6\n",
      "Predicted reward: [[-0.25291175 -0.3244664  -0.2896135  -0.2337831 ]]\n",
      "Buffer size: 26082\n",
      "Saving to checkpoint...\n",
      "[225] Average reward: -0.8\n",
      "Predicted reward: [[-0.20113312 -0.2822359  -0.06805125 -0.19668813]]\n",
      "Buffer size: 26883\n",
      "Saving to checkpoint...\n",
      "[230] Average reward: -0.8\n",
      "Predicted reward: [[ 0.08510923 -0.34597474  0.02831282 -0.15133876]]\n",
      "Buffer size: 28114\n",
      "Saving to checkpoint...\n",
      "[235] Average reward: -1.0\n",
      "Predicted reward: [[-0.3472065  -0.36484393 -0.3719202  -0.2252226 ]]\n",
      "Buffer size: 28668\n",
      "Saving to checkpoint...\n",
      "[240] Average reward: -0.4\n",
      "Predicted reward: [[-0.49423718 -0.53365594 -0.36627632 -0.38401353]]\n",
      "Buffer size: 29005\n",
      "Saving to checkpoint...\n",
      "[245] Average reward: -0.8\n",
      "Predicted reward: [[-0.05025167 -0.14189306 -0.25508732 -0.21997632]]\n",
      "Buffer size: 29417\n",
      "Saving to checkpoint...\n",
      "[250] Average reward: -0.8\n",
      "Predicted reward: [[-0.287834   -0.32435343 -0.05424391 -0.2535376 ]]\n",
      "Buffer size: 29848\n",
      "Saving to checkpoint...\n",
      "[255] Average reward: -0.6\n",
      "Predicted reward: [[ 0.00052517 -0.09772763 -0.16666189 -0.04239544]]\n",
      "Buffer size: 30455\n",
      "Saving to checkpoint...\n",
      "[260] Average reward: -0.6\n",
      "Predicted reward: [[-0.10970484 -0.24241856  0.19139567 -0.10245517]]\n",
      "Buffer size: 31306\n",
      "Saving to checkpoint...\n",
      "[265] Average reward: -1.0\n",
      "Predicted reward: [[ 0.03303356 -0.08693922  0.06452657 -0.18770035]]\n",
      "Buffer size: 31563\n",
      "Saving to checkpoint...\n",
      "[270] Average reward: -0.4\n",
      "Predicted reward: [[0.0781237  0.04458797 0.07353188 0.09869164]]\n",
      "Buffer size: 32368\n",
      "Saving to checkpoint...\n",
      "[275] Average reward: -1.0\n",
      "Predicted reward: [[-0.1707549  -0.24640499 -0.1158556  -0.36464465]]\n",
      "Buffer size: 32584\n",
      "Saving to checkpoint...\n",
      "[280] Average reward: -1.0\n",
      "Predicted reward: [[-0.0168706  -0.12581234 -0.00870453 -0.08988225]]\n",
      "Buffer size: 32868\n",
      "Saving to checkpoint...\n",
      "[285] Average reward: -0.8\n",
      "Predicted reward: [[-0.06512431 -0.34245038 -0.25333366 -0.21066555]]\n",
      "Buffer size: 33230\n",
      "Saving to checkpoint...\n",
      "[290] Average reward: -0.8\n",
      "Predicted reward: [[ 0.26228267 -0.01374385  0.2759338   0.14660831]]\n",
      "Buffer size: 33421\n",
      "Saving to checkpoint...\n",
      "[295] Average reward: -1.0\n",
      "Predicted reward: [[-0.18621626 -0.2329456  -0.25097832 -0.2664141 ]]\n",
      "Buffer size: 33593\n",
      "Saving to checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300] Average reward: -0.4\n",
      "Predicted reward: [[-0.21999177 -0.19345817 -0.27021182 -0.24769203]]\n",
      "Buffer size: 33767\n",
      "Saving to checkpoint...\n",
      "[305] Average reward: -0.8\n",
      "Predicted reward: [[ 0.05773135 -0.14098406  0.05218875 -0.12361807]]\n",
      "Buffer size: 34403\n",
      "Saving to checkpoint...\n",
      "[310] Average reward: -1.0\n",
      "Predicted reward: [[0.26641798 0.11854055 0.2757152  0.2007705 ]]\n",
      "Buffer size: 34919\n",
      "Saving to checkpoint...\n",
      "[315] Average reward: -1.0\n",
      "Predicted reward: [[-0.02143336 -0.0580307   0.00232598 -0.11535773]]\n",
      "Buffer size: 35236\n",
      "Saving to checkpoint...\n",
      "[320] Average reward: -1.0\n",
      "Predicted reward: [[-0.09193728 -0.18681043 -0.02021901 -0.08801465]]\n",
      "Buffer size: 35403\n",
      "Saving to checkpoint...\n",
      "[325] Average reward: -0.6\n",
      "Predicted reward: [[-0.10219733  0.07371285 -0.05119086  0.12247571]]\n",
      "Buffer size: 35841\n",
      "Saving to checkpoint...\n",
      "[330] Average reward: -0.4\n",
      "Predicted reward: [[-0.13370283 -0.25286472  0.01367985 -0.00959967]]\n",
      "Buffer size: 36466\n",
      "Saving to checkpoint...\n",
      "[335] Average reward: -1.0\n",
      "Predicted reward: [[-0.20464776 -0.16587889 -0.14488459 -0.14661688]]\n",
      "Buffer size: 36704\n",
      "Saving to checkpoint...\n",
      "[340] Average reward: -0.6\n",
      "Predicted reward: [[-0.19358364 -0.13286886 -0.26817963 -0.35084966]]\n",
      "Buffer size: 37019\n",
      "Saving to checkpoint...\n",
      "[345] Average reward: -0.8\n",
      "Predicted reward: [[-0.20036131 -0.21222404 -0.07349831 -0.20291527]]\n",
      "Buffer size: 37244\n",
      "Saving to checkpoint...\n",
      "[350] Average reward: -1.0\n",
      "Predicted reward: [[-0.13735384 -0.20024791 -0.03614238 -0.20051634]]\n",
      "Buffer size: 37604\n",
      "Saving to checkpoint...\n",
      "[355] Average reward: -1.0\n",
      "Predicted reward: [[-0.05095623 -0.2998594  -0.17026034 -0.21340996]]\n",
      "Buffer size: 37913\n",
      "Saving to checkpoint...\n",
      "[360] Average reward: -1.0\n",
      "Predicted reward: [[ 0.13501452  0.40135545 -0.10298388  0.11316617]]\n",
      "Buffer size: 38322\n",
      "Saving to checkpoint...\n",
      "[365] Average reward: -1.0\n",
      "Predicted reward: [[-0.26403618 -0.23154667 -0.27774516 -0.32930788]]\n",
      "Buffer size: 38639\n",
      "Saving to checkpoint...\n",
      "[370] Average reward: -0.6\n",
      "Predicted reward: [[ 0.01615065 -0.2039104   0.07551309 -0.12426041]]\n",
      "Buffer size: 39493\n",
      "Saving to checkpoint...\n",
      "[375] Average reward: -0.8\n",
      "Predicted reward: [[-0.01107895 -0.13043651 -0.05856325 -0.23302601]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[380] Average reward: -0.8\n",
      "Predicted reward: [[-0.12506193 -0.17085914 -0.05690401 -0.07482077]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[385] Average reward: -0.8\n",
      "Predicted reward: [[0.1014154  0.05323401 0.11139798 0.14153138]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[390] Average reward: -0.8\n",
      "Predicted reward: [[-0.09797028 -0.17252968 -0.11681031 -0.16522455]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[395] Average reward: -0.8\n",
      "Predicted reward: [[-0.16591366 -0.21615577 -0.02774595 -0.23443508]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[400] Average reward: -1.0\n",
      "Predicted reward: [[-0.04566793 -0.08412372 -0.07998617 -0.14375034]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[405] Average reward: -0.6\n",
      "Predicted reward: [[-0.10049315 -0.19046327  0.10486518 -0.05951782]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[410] Average reward: -0.8\n",
      "Predicted reward: [[-0.14840087 -0.12516193 -0.05788587 -0.02724592]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[415] Average reward: -1.0\n",
      "Predicted reward: [[-0.08620847 -0.39909884 -0.23035055 -0.24318591]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[420] Average reward: -1.0\n",
      "Predicted reward: [[-0.06833208 -0.0077923   0.00537871 -0.09883793]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[425] Average reward: -0.8\n",
      "Predicted reward: [[ 0.2535741   0.09933927  0.28584933 -0.05976266]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[430] Average reward: -1.0\n",
      "Predicted reward: [[-0.1841174  -0.1542952  -0.12669903 -0.11453017]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[435] Average reward: -0.8\n",
      "Predicted reward: [[ 0.02989749 -0.05578722  0.15114512 -0.04084561]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[440] Average reward: -0.8\n",
      "Predicted reward: [[-0.18706542 -0.23173276 -0.11835173 -0.14681958]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[445] Average reward: -0.8\n",
      "Predicted reward: [[-0.07023706 -0.2792005   0.02690569 -0.16943277]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[450] Average reward: -1.0\n",
      "Predicted reward: [[-0.05397164 -0.09576932  0.00652786 -0.11289389]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[455] Average reward: -1.0\n",
      "Predicted reward: [[ 0.41250196  0.2986283   0.29234365 -0.02698333]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[460] Average reward: -1.0\n",
      "Predicted reward: [[-0.01970417 -0.2133752   0.01382894 -0.25867367]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[465] Average reward: -0.6\n",
      "Predicted reward: [[ 0.0379255  -0.1416419   0.19906676 -0.14547369]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[470] Average reward: -0.8\n",
      "Predicted reward: [[-0.26164436 -0.31185845 -0.10484416 -0.4038849 ]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[475] Average reward: -0.8\n",
      "Predicted reward: [[ 0.04324689 -0.02791785  0.11399233 -0.06649631]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[480] Average reward: -0.4\n",
      "Predicted reward: [[-0.12280657 -0.11073703 -0.03200452 -0.11225785]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[485] Average reward: -0.8\n",
      "Predicted reward: [[0.475378   0.11060423 0.3275906  0.18124694]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[490] Average reward: -0.8\n",
      "Predicted reward: [[ 0.0607167  -0.11963668 -0.06556172 -0.18193868]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[495] Average reward: -1.0\n",
      "Predicted reward: [[ 0.16484341 -0.00723282  0.0443394  -0.02800232]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[500] Average reward: -0.8\n",
      "Predicted reward: [[-0.12899834 -0.12963948 -0.05749507 -0.22790092]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[505] Average reward: -1.0\n",
      "Predicted reward: [[-0.03924091 -0.02869078  0.13828291 -0.13570552]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n",
      "[510] Average reward: -1.0\n",
      "Predicted reward: [[ 0.52041507 -0.06504685  0.61239135  0.4848508 ]]\n",
      "Buffer size: 40000\n",
      "Saving to checkpoint...\n"
     ]
    }
   ],
   "source": [
    "if action == 'train':\n",
    "    if 'DQN' in \"\\n\".join(algo):\n",
    "        # fill buffer with some random samples\n",
    "        for i in tqdm(range(500)):\n",
    "            agent.collect_rollout(t_max=t_max, policy=lambda x: np.random.choice(4), train=False, display=False)\n",
    "        #print(agent.epsilon)\n",
    "        #agent.epsilon = 0.05\n",
    "        hist += agent.train(epochs=config['train_epochs'], t_max=t_max, display=False)\n",
    "    elif 'PPO' in \"\\n\".join(algo):\n",
    "        agent.train(epochs=config['train_epochs'], t_max=t_max, buf_size=3000, min_buf_size=600, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "a = hist[::1]\n",
    "plt.plot(range(len(a)), a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rollout(t_max, env, close=True):\n",
    "    import sys\n",
    "    obs = agent.preprocess(env.reset())\n",
    "    reward = 0\n",
    "    for i in range(t_max):\n",
    "        # print(agent.get_policy(obs))\n",
    "        # act = agent.get_action(obs, greedy=True)[0]\n",
    "        act = agent.get_action(obs, mode='greedy')[0][0]\n",
    "        obs, r, dn, info = env.step(agent.action_wrapper(act))\n",
    "        env.render()\n",
    "        print(act, file=sys.stderr)\n",
    "        time.sleep(0.05)\n",
    "        obs = agent.preprocess(obs)\n",
    "        reward += r\n",
    "        if dn:\n",
    "            break\n",
    "\n",
    "    print(\"Total reward: {}\".format(reward), file=sys.stderr)\n",
    "    if close: env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if action == 'test':\n",
    "    test_rollout(10000, env, close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.train(4, t_max=500, min_buf_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f agent.train agent.train(1, t_max=500, buf_size=2000, min_buf_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
